<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>Monte Carlo Methods</title>
    <link rel="stylesheet" href="../../style.css">
    <script src="../../index.js"></script>
</head>
<body>
    <header>
        <nav class="corporate-nav">
            <div class="nav-container">
                <div class="title-header">
                    <h1 class="title">Monte Carlo Methods</h1>
                    <p class="subtitle">
                        Monte Carlo methods let a machine learn by trial and error using random simulations.
Here‚Äôs the simplest explanation of how machine learning works in Monte Carlo (MC) approaches):
                    </p>
                </div>        
            </div>
        </nav>
    </header>

    <main>
        <section>
            <h2>‚úÖ How Monte Carlo Helps a Machine Learn</h2>
            <p>Monte Carlo is used to estimate the value of actions or states by running many random simulations and averaging the results.</p>
            <p>It‚Äôs like the machine asking:</p>
            <p>‚ÄúIf I try this many times in random situations, what is the average outcome?‚Äù</p>
        </section>

        <section>
            <h2>‚úÖ 1. Run Random Simulations</h2>
            <p>The machine plays many random games or executes random sequences of actions.</p>
            <p>Example (chess or Go):</p>
            <ul>
                <li>It chooses a random legal move.</li>
                <li>It plays randomly until the game ends.</li>
                <li>It records: win / loss / draw.</li>
            </ul>
            <p>This is one Monte Carlo rollout.</p>
        </section>

        <section>
            <h2>‚úÖ 2. Collect Outcomes</h2>
            <p>After thousands or millions of rollouts, it gets statistics:</p>
            <p>Example:</p>
            <ul>
                <li>Move A ‚Üí 10,000 simulations ‚Üí 5,700 wins ‚Üí 57% win rate</li>
                <li>Move B ‚Üí 10,000 simulations ‚Üí 4,300 wins ‚Üí 43% win rate</li>
            </ul>
            <p>The machine learns which choices lead to better outcomes.</p>
        </section>

        <section>
            <h2>‚úÖ 3. Update Value Estimates (Learning)</h2>
            <p>MC learning uses formulas like:</p>
            <pre><code>
NewValue = OldValue + learningRate √ó (ObservedReturn ‚àí OldValue)
            </code></pre>
            <p>This gradually adjusts the value of a move, state, or action.</p>
            <p>The more simulations ‚Üí the more accurate the value.</p>
        </section>

        <section>
            <h2>‚úÖ 4. Use the Best Move Based on Statistics</h2>
            <p>After enough learning, the machine chooses the move with the highest estimated value (win rate, reward, score).</p>
        </section>

        <section>
            <h2>üß† Monte Carlo in Machine Learning</h2>
            <p>There are 2 major ways Monte Carlo is used:</p>

            <p>A. Monte Carlo Reinforcement Learning</p>
            <p>Used when:</p>
            <ul>
                <li>You can simulate the environment</li>
                <li>You can wait until the end of an episode (full game/run)</li>
            </ul>
            <p>The machine:</p>
            <ol>
                <li>Plays an episode</li>
                <li>Observes reward at the end</li>
                <li>Updates policy/values based on the outcome</li>
            </ol>
            <p>This is used in:</p>
            <ul>
                <li>Blackjack learning</li>
                <li>Simple games</li>
                <li>Teaching agents good long-term strategies</li>
            </ul>
        </section>

        <section>
            <h2>B. Monte Carlo Tree Search (MCTS)</h2>
            <p>This is used in:</p>
            <ul>
                <li>Chess engines</li>
                <li>Go (AlphaGo)</li>
                <li>Modern planning AI</li>
            </ul>
            <p>The machine:</p>
            <ol>
                <li>Selects a promising move in the search tree</li>
                <li>Simulates random games (rollouts)</li>
                <li>Backpropagates results up the tree</li>
                <li>Updates values of moves</li>
            </ol>
            <p>After thousands of simulations, the tree becomes more accurate.</p>
            <p>MCTS = random simulations ‚Üí statistics ‚Üí improve decisions.</p>
        </section>

        <section>
            <h2>üéØ Simple Example</h2>
            <p>Let‚Äôs say a machine wants to learn if it should go left or right.</p>
            <p>It tries 10,000 random simulations:</p>
            <p>Going Left:</p>
            <ul>
                <li>70% chance of reward</li>
                <li>30% chance of failure</li>
            </ul>
            <p>Going Right:</p>
            <ul>
                <li>40% chance of reward</li>
                <li>60% chance of failure</li>
            </ul>
            <p>Machine learns:</p>
            <p>Left is better ‚Üí choose Left.</p>
            <p>That's Monte Carlo learning.</p>
        </section>

        <section>
            <h2>üìå In One Sentence</h2>
            <p>A machine learns in Monte Carlo by running many random simulations, collecting outcomes, estimating the value of actions, and improving its decisions from these statistics.</p>
        </section>

        <section>
            <p>If you want, I can also explain:</p>
            <p>‚úÖ Monte Carlo Tree Search flow</p>
            <p>‚úÖ How AlphaGo uses Monte Carlo + neural networks</p>
            <p>‚úÖ How Monte Carlo compares to minimax</p>
        </section>
    </main>

    <footer>
        <p class="copyright">
            &copy; <span id="year"></span> Aether Corp. All rights reserved.
        </p>
    </footer>
</body>
</html>
